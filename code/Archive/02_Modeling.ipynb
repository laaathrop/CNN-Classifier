{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOKfKSeTcYyR"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1db7cb508d39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Deep Learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# For functions pertaining to the operating system\n",
    "import os\n",
    "\n",
    "# Module for working with URLs\n",
    "import urllib\n",
    "\n",
    "# For performing operations on zip files\n",
    "import zipfile\n",
    "\n",
    "# Makes it possible to read and write tar archives including gzip, bz2 and lzma compression\n",
    "import tarfile\n",
    "\n",
    "# Module for working with URLs\n",
    "from six.moves import urllib\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.training import HParams\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, AveragePooling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Visualization\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nO3ZOEXgnYe"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'HParams'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e6cfd8385e1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m params = tf.HParams(\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Number of classes in the Cifar 10 dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# How much to change the model in response to the estimated error each time the weights are updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'HParams'"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "params = HParams(\n",
    "    \n",
    "    n_classes=10, # Number of classes in the Cifar 10 dataset\n",
    "    learning_rate=1e-4, # How much to change the model in response to the estimated error each time the weights are updated\n",
    "    train_batch_size=32, # Training batch size; number of data points in one forward/backward pass\n",
    "    val_batch_size=32, # Batch size for validation; number of data points in one forward/backward pass\n",
    "    test_batch_size=32, # Testing batch size; number of data points in one forward/backward pass\n",
    "    n_epochs=10, # One epoch is equivalent to one forward and one backward pass of all training data points\n",
    "    input_name='input_one', # Name of NN input layer\n",
    "    data_dir='/tmp/cifar-data/' # Path to data\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63_hSJvQ0Yzo"
   },
   "outputs": [],
   "source": [
    "# Dimension of the square image\n",
    "n_pixels = 32\n",
    "\n",
    "# Number of image color channels\n",
    "n_channels = 3\n",
    "\n",
    "# Length of flattened image\n",
    "size_flat = n_channels * (n_pixels**2)\n",
    "\n",
    "# Number of classes considered\n",
    "n_classes = params.n_classes\n",
    "\n",
    "# Quantity of files in the original dataset\n",
    "_n_files_train = 1\n",
    "\n",
    "# Quantity of training images\n",
    "_n_images_train = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJpOzA9y1_b1"
   },
   "outputs": [],
   "source": [
    "def extract_data(destination):\n",
    "    \"\"\"\n",
    "    Description - Extracts the data into the directory specified by the params \n",
    "                  class.\n",
    "\n",
    "    Returns - N/A\n",
    "    \"\"\"\n",
    "\n",
    "    # Set filename\n",
    "    filename = 'cifar-100-python.tar.gz'\n",
    "\n",
    "    # Create the final file path\n",
    "    destination_path = os.path.join(destination, filename)\n",
    "\n",
    "    # If the file does not exist, \n",
    "    if not os.path.exists(destination_path):\n",
    "\n",
    "        # If the directory does not exist,\n",
    "        if not os.path.exists(destination):\n",
    "\n",
    "            # Create the needed directory \n",
    "            os.makedirs(destination)\n",
    "\n",
    "        # Download the dataset using urllib\n",
    "        destination_path, _ = urllib.request.urlretrieve(url=url, filename=destination_path)\n",
    "\n",
    "        # Print a status message\n",
    "        print()\n",
    "        print(\"Step (1/2) - Files have been downloaded.\")\n",
    "\n",
    "        # If we are dealing with a zip file,\n",
    "        if destination_path.endswith(\".zip\"):\n",
    "\n",
    "            # extract the zipfile into the desitnation directory\n",
    "            zipfile.ZipFile(file=destination_path, mode=\"r\").extractall(destination)\n",
    "\n",
    "        # If we are dealing with a tar file, extract with tarfile\n",
    "        elif destination_path.endswith((\".tar.gz\", \".tgz\")):\n",
    "\n",
    "            # Extract the tarfile into the desitnation directory\n",
    "            tarfile.open(name=destination_path, mode=\"r:gz\").extractall(destination)\n",
    "\n",
    "            # Print a status message\n",
    "            print(\"Step (2/2) - Files have been extracted.\")\n",
    "\n",
    "    # If the data does exist, \n",
    "    else:\n",
    "\n",
    "        # Print a status message\n",
    "        print(\"Data has apparently already been saved locally and extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1gF2y-uKQvo"
   },
   "outputs": [],
   "source": [
    "def _get_file_path(filename=\"\"):\n",
    "    \"\"\"\n",
    "    Description - Finds and returns the data path location.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the join method to create the path\n",
    "    return os.path.join(params.data_dir, \"cifar-100-python/\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nz826-MrL4dc"
   },
   "outputs": [],
   "source": [
    "def _unpickle(filename):\n",
    "    \"\"\"\n",
    "    Description - Unpickle (de-serialize) the given file pieces and return the \n",
    "                  aggregated data chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the file path using the function defined above\n",
    "    destination_path = _get_file_path(filename)\n",
    "\n",
    "    # Print a status message\n",
    "    print(\"Currently loading data from: \" + destination_path)\n",
    "\n",
    "    # Open the file located at file_path\n",
    "    with open(destination_path, mode='rb') as file:\n",
    "\n",
    "        # Load the data into a new variable using Pickle's load method\n",
    "        data = pickle.load(file, encoding='bytes')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V34c8ImFPXgU"
   },
   "outputs": [],
   "source": [
    "def _convert_images(raw_data):\n",
    "    \"\"\"\n",
    "    Description - Preprocesses raw image data and convert to a 4-dimensional \n",
    "    array: [image_number, height, width, channel]\n",
    "   \n",
    "    Returns - The preprocessed and scaled image data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Scale the pixel data\n",
    "    scaled_data = np.array(raw_data, dtype=float) / 255.0\n",
    "\n",
    "    # Change the shape of the array to 4-D\n",
    "    images = scaled_data.reshape([-1, n_channels, img_size, img_size])\n",
    "\n",
    "    # Reindex the array\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ih3F_4xkSa5i"
   },
   "outputs": [],
   "source": [
    "def _load_data(filename):\n",
    "    \"\"\"\n",
    "    Description - Unpickles (de-serializes) the input file and converts the data\n",
    "                  to the data shape specified in the _convert_data function.\n",
    "    \n",
    "    Returns - The converted data and the class label for each image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpickle the data\n",
    "    data = _unpickle(filename)\n",
    "\n",
    "    # Retrieve the raw image pixel data\n",
    "    raw_images = data[b'data']\n",
    "\n",
    "    # Arrange the class labels into a numpy array\n",
    "    classes = np.array(data[b'labels'])\n",
    "\n",
    "    # Convert the image pixel size/orientation\n",
    "    images = _convert_images(raw_images)\n",
    "\n",
    "    return images, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPribww2Wbzp"
   },
   "outputs": [],
   "source": [
    "def load_class_names():\n",
    "\n",
    "    # Unpickle the file and access the class label names\n",
    "    raw_classes = _unpickle(filename=\"meta\")[b'label_names']\n",
    "\n",
    "    # Convert from strings to a list\n",
    "    names = [x.decode('utf-8') for x in raw]\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61VRsgsVXK4W"
   },
   "outputs": [],
   "source": [
    "def load_training_data():\n",
    "    \"\"\"\n",
    "    Description - Builds numpy arrays containing the image data and the class \n",
    "                  labels from the 5 files in the Cifar 100 dataset.\n",
    "\n",
    "    Returns - The images and class labels for each training image data point \n",
    "              in the set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate memory for the images\n",
    "    images = np.zeros(shape=[_n_images_train, n_pixels, n_pixels, n_channels], dtype=float)\n",
    "\n",
    "    # Allocate memory for the class labels\n",
    "    classes = np.zeros(shape=[_n_images_train], dtype=int)\n",
    "\n",
    "    # Load the images and class labels from the training data\n",
    "    images, classes = _load_data(filename=\"train\")\n",
    "\n",
    "    return images, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjbAfESxUQ3c"
   },
   "outputs": [],
   "source": [
    "def load_validation_data():\n",
    "    \"\"\"\n",
    "    Description - Loads 5000 data points from the test batch file of the Cifar\n",
    "                  100 dataset to be used for validation.\n",
    "\n",
    "    Returns - The images and class labels for each validation image data point \n",
    "              in the set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the images and class labels from the test batch file\n",
    "    images, classes = _load_data(filename=\"test\")\n",
    "\n",
    "    # Define the validation data to be all but the first 5000 data points\n",
    "    images = images[5000:, :, :, :]\n",
    "    classes = classes[5000:]\n",
    "\n",
    "    return images, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_l7yYF0tKFdf"
   },
   "outputs": [],
   "source": [
    "def load_testing_data():\n",
    "    \"\"\"\n",
    "    Description - Loads 5000 data points from the test batch file of the Cifar\n",
    "                  100 dataset to be used for testing.\n",
    "\n",
    "    Returns - The images and class labels for each testing image data point \n",
    "              in the set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the unpickled and converted data\n",
    "    images, classes = _load_data(filename=\"test\")\n",
    "\n",
    "    # Define the testing data to be the first 5000 data points\n",
    "    images = images[:5000, :, :, :]\n",
    "    classes = classes[:5000]\n",
    "\n",
    "    return images, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UFWuI_B9BHLK"
   },
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs - This is the 4-D tensor input from the image preprocessing step\n",
    "        num_filters - The number of image convolution filters\n",
    "        kernel_size - Dimensions of the 2D convolution window\n",
    "        strides - Specifies the number of strides along the height and width\n",
    "        activation - Neural network activation function\n",
    "        batch_normalization - Normalize the activations at each layer\n",
    "        conv_first - Use true to indicate conv-bn-activation; use false\n",
    "                     to indicate bn-activation-conv\n",
    "            \n",
    "    # Returns\n",
    "        x - Tensor that is used as an input to the next layer\n",
    "    \"\"\"\n",
    "\n",
    "    # Declare a 2 dimensional convolutional layer; params above\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(1e-4))\n",
    "\n",
    "    # X is the number of inputs\n",
    "    x = inputs\n",
    "\n",
    "    # If conv_first is True, apply conv to x\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        # If batch_normalization is True, apply BN to x\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        # If activation has some value, apply activation to x\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    # Else, apply conv to x after applying BN and activation\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, batch_size=1024, depth=20, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape - Dimensions of the input image tensor\n",
    "        depth - Number of convolutional layers\n",
    "        num_classes - Total number of class labels\n",
    "    # Returns\n",
    "        model - A Keras model\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "      \n",
    "\n",
    "    # Number of input filters\n",
    "    num_filters_in = 16\n",
    "\n",
    "    # Number of residual blocks\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    # Define input layer with given input shape and batch size\n",
    "    inputs = Input(shape=input_shape, batch_size=batch_size)\n",
    "                   \n",
    "    \n",
    "    # Create a residual layer\n",
    "    x = resnet_layer(inputs=inputs, num_filters=num_filters_in, conv_first=True)\n",
    "                     \n",
    "    # Create three stages\n",
    "    for stage in range(3):\n",
    "\n",
    "        # Create a number of residual blocks\n",
    "        for res_block in range(num_res_blocks):\n",
    "\n",
    "            # Use the rectified linear unit\n",
    "            activation = 'relu'\n",
    "\n",
    "            # Set mean to zero and standard deviation to 1\n",
    "            batch_normalization = True\n",
    "\n",
    "            # This will set the number of strides across the image to 1\n",
    "            strides = 1\n",
    "\n",
    "            # At the first stage\n",
    "            if stage == 0:\n",
    "\n",
    "                # Set the number of output filters\n",
    "                num_filters_out = num_filters_in * 4\n",
    "\n",
    "                # This is the first layer in the first stage\n",
    "                if res_block == 0:  \n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "\n",
    "            # At all other stages\n",
    "            else:\n",
    "\n",
    "                # Set the number of output filters\n",
    "                num_filters_out = num_filters_in * 2\n",
    "\n",
    "                # At the first layer\n",
    "                if res_block == 0: \n",
    "\n",
    "                    # This is amount by which the filter shifts across the image\n",
    "                    strides = 2    \n",
    "\n",
    "            # These are the residual layers\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            \n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            \n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            \n",
    "            # At the first layer\n",
    "            if res_block == 0:\n",
    "\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "                \n",
    "            x = tf.keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(lr=params.learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0IthT4zHwlz"
   },
   "outputs": [],
   "source": [
    "# # Set the verbosity of TensorFlow\n",
    "# tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "# # Define the residual net layer using resnet v2; borrowed from the official Keras examples\n",
    "# model = resnet_v2((32, 32, 3), depth=56, num_classes=params.n_classes)\n",
    "\n",
    "# # Set model variables\n",
    "# X_train, y_train = load_training_data()\n",
    "\n",
    "# # Set validation variables\n",
    "# X_val, y_val = load_validation_data()\n",
    "\n",
    "# # Set model testing variables\n",
    "# X_test, y_test = load_testing_data()\n",
    "\n",
    "# # This will enable use of the TensorBoard for visualization\n",
    "# callbacks = [ tf.keras.callbacks.TensorBoard(log_dir=params.checkpoint_dir) ]\n",
    "\n",
    "# # Preprocess and augment the data\n",
    "# # (Fill in argument comments)\n",
    "# augmented = ImageDataGenerator(\n",
    "    \n",
    "#     featurewise_center=False, # \n",
    "#     samplewise_center=False, #\n",
    "#     featurewise_std_normalization=False, #\n",
    "#     samplewise_std_normalization=False, #\n",
    "#     zca_whitening=False, #\n",
    "#     zca_epsilon=1e-6, #\n",
    "#     rotation_range=0, #\n",
    "#     width_shift_range=0.1, #\n",
    "#     height_shift_range=0.1, #\n",
    "#     fill_mode='nearest', #\n",
    "#     cval=0., #\n",
    "#     horizontal_flip=True, #\n",
    "#     vertical_flip=False #\n",
    "\n",
    "# )\n",
    "\n",
    "# # Generates preprocessed and augmented data for the purpose of improving\n",
    "# # the models ability to generalize to new data\n",
    "# augmented.fit(X_train)\n",
    "\n",
    "# # Fit the model; use fit_generator to account for the generator used to augment\n",
    "# # and preprocess the data\n",
    "# model.fit_generator(\n",
    "    \n",
    "#     augmented.flow(X_train, y_train, batch_size=params.train_batch_size),\n",
    "#     epochs=params.n_epochs,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     workers=4,\n",
    "#     callbacks=callbacks\n",
    "\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 352,
     "status": "error",
     "timestamp": 1575175297738,
     "user": {
      "displayName": "Anthony Lathrop",
      "photoUrl": "",
      "userId": "09824446360736258535"
     },
     "user_tz": 480
    },
    "id": "mGhMCYVbuh8V",
    "outputId": "9926a9b5-f063-49d7-d626-9e04d896f5dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently loading data from: /tmp/cifar-data/cifar-100-python/train\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-b2407b3d91ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-236-7c8854e7bd9f>\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Open the file located at file_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Load the data into a new variable using Pickle's load method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/cifar-data/cifar-100-python/train'"
     ]
    }
   ],
   "source": [
    "data = _unpickle('train')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "02_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
